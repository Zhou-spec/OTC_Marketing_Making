{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import torch\n",
    "\n",
    "T = torch.tensor([1])\n",
    "dt = torch.tensor([0.01])\n",
    "S0 = torch.tensor([1])\n",
    "q = torch.tensor([0.01])\n",
    "A = torch.tensor([2, 1.6, 1.2, 0.8, 0.4, 0.2])\n",
    "B = torch.tensor([1, 0.8, 0.6, 0.4, 0.2, 0.1])\n",
    "Q = torch.tensor([300]) \n",
    "z = torch.tensor([10, 20, 30, 40, 50, 60])\n",
    "delta = torch.tensor([0.01])\n",
    "gamma = torch.tensor([0.01])\n",
    "sigma = torch.tensor([0.05])\n",
    "\n",
    "# use cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "T = T.to(device)\n",
    "dt = dt.to(device)\n",
    "S0 = S0.to(device)\n",
    "q = q.to(device)\n",
    "A = A.to(device)\n",
    "B = B.to(device)\n",
    "Q = Q.to(device)\n",
    "z = z.to(device)\n",
    "delta = delta.to(device)\n",
    "gamma = gamma.to(device)\n",
    "sigma = sigma.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 p_loss:  -328.1642150878906\n",
      "epoch:  0 v_loss:  20751.04296875\n",
      "epoch:  1 p_loss:  -1033.2398681640625\n",
      "epoch:  1 v_loss:  111456.5625\n",
      "epoch:  2 p_loss:  -1202.9716796875\n",
      "epoch:  2 v_loss:  110305.625\n",
      "epoch:  3 p_loss:  -2246.6806640625\n",
      "epoch:  3 v_loss:  404437.125\n",
      "epoch:  4 p_loss:  -303.4521484375\n",
      "epoch:  4 v_loss:  13233.25390625\n",
      "epoch:  5 p_loss:  -530.731201171875\n",
      "epoch:  5 v_loss:  30771.921875\n",
      "epoch:  6 p_loss:  -100.3923110961914\n",
      "epoch:  6 v_loss:  3997.5126953125\n",
      "epoch:  7 p_loss:  -450.77166748046875\n",
      "epoch:  7 v_loss:  34670.25\n",
      "epoch:  8 p_loss:  -435.9366455078125\n",
      "epoch:  8 v_loss:  16955.6171875\n",
      "epoch:  9 p_loss:  -232.10438537597656\n",
      "epoch:  9 v_loss:  26390.7578125\n",
      "epoch:  10 p_loss:  -301.6378173828125\n",
      "epoch:  10 v_loss:  66247.9375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m optimizer_policy\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     18\u001b[0m optimizer_value\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     20\u001b[0m optimizer_policy\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     21\u001b[0m optimizer_value\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test the actor-critic method\n",
    "\n",
    "policy_net = ResNet_Conv(3, 12, 1, 2, 3, nn.Sigmoid())\n",
    "value_net = ResNet_Conv(3, 1, 1, 2, 3, nn.ReLU())\n",
    "policy_net.to(device)\n",
    "value_net.to(device)\n",
    "optimizer_policy = torch.optim.Adam(policy_net.parameters(), lr=0.01)\n",
    "optimizer_value = torch.optim.Adam(value_net.parameters(), lr=0.01)\n",
    "losses_actor_critic = []\n",
    "for epoch in range(50):\n",
    "    S, buy_orders, sell_orders, q, t, bid_vectors, ask_vectors = Test_Data_Simulation_Stochastic(T, dt, sigma, S0, policy_net, A, B, gamma, z)\n",
    "    v_loss = critic_loss(policy_net, value_net, S, q, t, buy_orders, sell_orders, T, dt, A, B, gamma, delta, z, Q)\n",
    "    p_loss = policy_loss(policy_net, value_net, S, q, t, buy_orders, sell_orders, bid_vectors, ask_vectors, T, dt, A, B, gamma, delta, z, Q)\n",
    "    # when we train the policy net, we need to detach the value net\n",
    "    loss = v_loss + p_loss\n",
    "    losses_actor_critic.append(loss.item())\n",
    "    optimizer_policy.zero_grad()\n",
    "    optimizer_value.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_policy.step()\n",
    "    optimizer_value.step()\n",
    "    print('epoch: ', epoch, 'p_loss: ', p_loss.item())\n",
    "    print('epoch: ', epoch, 'v_loss: ', v_loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_actor_critic = []\n",
    "for _ in range(50):\n",
    "    S, buy_orders, sell_orders, q, t, bid_vectors, ask_vectors = Test_Data_Simulation_Stochastic(T, dt, sigma, S0, policy_net, A, B, gamma, z)\n",
    "    N = int(T / dt)\n",
    "    r = torch.zeros(N, device = device)\n",
    "    for i in range(N - 1):\n",
    "        hold1 = z * buy_orders[i] * bid_vectors[i]\n",
    "        hold2 = z * sell_orders[i] * ask_vectors[i]\n",
    "        r[i] = torch.sum(hold1) + torch.sum(hold2)\n",
    "        r[i] = r[i] + (q[i + 1] * S[i + 1] - q[i] * S[i]) \n",
    "\n",
    "    trajectory_actor_critic.append(torch.sum(r).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
